{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kaggle_Titanic_utls import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(path / \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3838383838383838"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Survived'].sum()/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fare funzione Alessandro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are sufficiently balanced - it makes sense to consider accuracy as performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked only has 2 missing values out of 891 - we will get rid of them altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['Embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[['Survived']]\n",
    "\n",
    "data.drop(['Cabin', 'Ticket', 'PassengerId', 'Survived'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col0 {\n",
       "            background-color:  #ff00ff;\n",
       "            color:  #f1f1f1;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col1 {\n",
       "            background-color:  #00ffff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col2 {\n",
       "            background-color:  #4cb3ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col3 {\n",
       "            background-color:  #2cd3ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col4 {\n",
       "            background-color:  #00ffff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col0 {\n",
       "            background-color:  #1ee1ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col1 {\n",
       "            background-color:  #ff00ff;\n",
       "            color:  #f1f1f1;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col2 {\n",
       "            background-color:  #00ffff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col3 {\n",
       "            background-color:  #00ffff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col4 {\n",
       "            background-color:  #6a95ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col0 {\n",
       "            background-color:  #6897ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col1 {\n",
       "            background-color:  #0af5ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col2 {\n",
       "            background-color:  #ff00ff;\n",
       "            color:  #f1f1f1;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col3 {\n",
       "            background-color:  #817eff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col4 {\n",
       "            background-color:  #758aff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col0 {\n",
       "            background-color:  #5da2ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col1 {\n",
       "            background-color:  #21deff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col2 {\n",
       "            background-color:  #8d72ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col3 {\n",
       "            background-color:  #ff00ff;\n",
       "            color:  #f1f1f1;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col4 {\n",
       "            background-color:  #7e81ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col0 {\n",
       "            background-color:  #00ffff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col1 {\n",
       "            background-color:  #56a9ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col2 {\n",
       "            background-color:  #5ba4ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col3 {\n",
       "            background-color:  #57a8ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }    #T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col4 {\n",
       "            background-color:  #ff00ff;\n",
       "            color:  #f1f1f1;\n",
       "            font-size:  15px;\n",
       "        }</style><table id=\"T_a6887334_7f26_11eb_b409_2b9db7a510af\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Pclass</th>        <th class=\"col_heading level0 col1\" >Age</th>        <th class=\"col_heading level0 col2\" >SibSp</th>        <th class=\"col_heading level0 col3\" >Parch</th>        <th class=\"col_heading level0 col4\" >Fare</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a6887334_7f26_11eb_b409_2b9db7a510aflevel0_row0\" class=\"row_heading level0 row0\" >Pclass</th>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col1\" class=\"data row0 col1\" >-0.365902</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col2\" class=\"data row0 col2\" >0.081656</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col3\" class=\"data row0 col3\" >0.016824</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow0_col4\" class=\"data row0 col4\" >-0.548193</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a6887334_7f26_11eb_b409_2b9db7a510aflevel0_row1\" class=\"row_heading level0 row1\" >Age</th>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col0\" class=\"data row1 col0\" >-0.365902</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col2\" class=\"data row1 col2\" >-0.307351</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col3\" class=\"data row1 col3\" >-0.187896</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow1_col4\" class=\"data row1 col4\" >0.093143</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a6887334_7f26_11eb_b409_2b9db7a510aflevel0_row2\" class=\"row_heading level0 row2\" >SibSp</th>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col0\" class=\"data row2 col0\" >0.081656</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col1\" class=\"data row2 col1\" >-0.307351</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col3\" class=\"data row2 col3\" >0.414542</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow2_col4\" class=\"data row2 col4\" >0.160887</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a6887334_7f26_11eb_b409_2b9db7a510aflevel0_row3\" class=\"row_heading level0 row3\" >Parch</th>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col0\" class=\"data row3 col0\" >0.016824</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col1\" class=\"data row3 col1\" >-0.187896</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col2\" class=\"data row3 col2\" >0.414542</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow3_col4\" class=\"data row3 col4\" >0.217532</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a6887334_7f26_11eb_b409_2b9db7a510aflevel0_row4\" class=\"row_heading level0 row4\" >Fare</th>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col0\" class=\"data row4 col0\" >-0.548193</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col1\" class=\"data row4 col1\" >0.093143</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col2\" class=\"data row4 col2\" >0.160887</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col3\" class=\"data row4 col3\" >0.217532</td>\n",
       "                        <td id=\"T_a6887334_7f26_11eb_b409_2b9db7a510afrow4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fec9d79a520>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().style.background_gradient(cmap ='cool')\\\n",
    "        .set_properties(**{'font-size': '15px'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no highly correlated features (maybe do feature extraction?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the title of each passenger from the name **(which is most likely not useful in the prediction. We can check this though)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = data.Name.apply(lambda x:x.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            181\n",
       "Mrs             124\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Major             2\n",
       "Col               2\n",
       "Mlle              2\n",
       "Sir               1\n",
       "Capt              1\n",
       "Mme               1\n",
       "the Countess      1\n",
       "Jonkheer          1\n",
       "Don               1\n",
       "Ms                1\n",
       "Lady              1\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'] = title\n",
    "data.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((889, 1), (889, 8))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num, data_cat = get_features_by_type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = preprocessing(data_num, data_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_num.fillna(data_num.median(), inplace=True)\n",
    "data_cat.fillna(data_cat.mode(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "data_num_scaled = scaler.fit_transform(data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_cat_dummy = pd.get_dummies(data_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_ = np.c_[data_num_scaled, data_cat_dummy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_, labels,\n",
    "                            random_state=1, test_size=0.25, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at various baseline models to check which ones give the best score in and out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mknn scores\u001b[0m: {'train_score': 0.8528528528528528, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mLR scores\u001b[0m: {'train_score': 0.8273273273273273, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mtree scores\u001b[0m: {'train_score': 0.9834834834834835, 'test_score': 0.7757847533632287}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mGNB scores\u001b[0m: {'train_score': 0.6291291291291291, 'test_score': 0.6322869955156951}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mperceptron scores\u001b[0m: {'train_score': 0.7672672672672672, 'test_score': 0.7533632286995515}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mSVC scores\u001b[0m: {'train_score': 0.8378378378378378, 'test_score': 0.8430493273542601}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {'knn': KNeighborsClassifier(), 'LR': LogisticRegression(), \n",
    "         'tree': DecisionTreeClassifier(), 'GNB': GaussianNB(),\n",
    "         'perceptron': Perceptron(), 'SVC': SVC()}\n",
    "\n",
    "for i, j in models.items():\n",
    "    scores = model_trial(data_, labels, j)\n",
    "    print(color.BOLD + color.RED + color.UNDERLINE + f'{i} scores' + color.END + f': {scores}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron and Naive Bayes have a poor accuracy, whereas Decision Trees are clearly overfitting to the training set. SVC, Logistic Regression and KNN perform reasonably well in and out of sample (random guess would yield around $62 \\%$ accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the impact that different imputation strategies bear on the accuracy of the models. In the following we have imputed missing values with mean, median and with zeros, and have assessed the effect of these on the three best performing models we have previously selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num, data_cat = get_features_by_type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4m('LR', 'median') scores\u001b[0m: {'train_score': 0.8273273273273273, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('SVC', 'median') scores\u001b[0m: {'train_score': 0.8378378378378378, 'test_score': 0.8430493273542601}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('knn', 'median') scores\u001b[0m: {'train_score': 0.8528528528528528, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('LR', 'mean') scores\u001b[0m: {'train_score': 0.8273273273273273, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('SVC', 'mean') scores\u001b[0m: {'train_score': 0.8378378378378378, 'test_score': 0.8430493273542601}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('knn', 'mean') scores\u001b[0m: {'train_score': 0.8528528528528528, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('LR', 'zero') scores\u001b[0m: {'train_score': 0.8273273273273273, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('SVC', 'zero') scores\u001b[0m: {'train_score': 0.8378378378378378, 'test_score': 0.8430493273542601}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4m('knn', 'zero') scores\u001b[0m: {'train_score': 0.8528528528528528, 'test_score': 0.8385650224215246}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputation_dict = {'median': data_num.median(), 'mean': data_num.mean(), 'zero': 0}\n",
    "\n",
    "models = {'LR': LogisticRegression(), 'SVC': SVC(), 'knn': KNeighborsClassifier()}\n",
    "\n",
    "for key, value in imputation_dict.items():\n",
    "    data_ = preprocessing(data_num, data_cat, imputer_num=key)\n",
    "    for k, v in models.items():\n",
    "        scores = model_trial(data_, labels, model=v)\n",
    "        print(color.BOLD + color.RED + color.UNDERLINE + f'{k, key} scores' + color.END + f': {scores}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imputation strategies considered bear no effect on the accuracy of any of the models. We will however keep the median as default imputation method as it is more robust than the mean and contains more information about the data than the zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take the best models and preprocessing strategies and grid search the best parameters using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num, data_cat = get_features_by_type(data)\n",
    "data_ = preprocessing(data_num, data_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'weights': ['uniform', 'distance'], \n",
    "               'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "               'n_neighbors': np.linspace(1, 15, 15).astype(int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(models['knn'], cv=4, n_jobs=-3, param_grid=param_grid, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done 100 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 318 ms, sys: 76.5 ms, total: 395 ms\n",
      "Wall time: 1.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Done 480 out of 480 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=KNeighborsClassifier(), n_jobs=-3,\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gscv.fit(data_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(KNeighborsClassifier(n_neighbors=12),\n",
       " {'algorithm': 'auto', 'n_neighbors': 12, 'weights': 'uniform'})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_, gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368953880764904"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_est_knn = gscv.best_estimator_\n",
    "best_est_knn.fit(data_, labels)\n",
    "best_est_knn.score(data_, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(models['LR'], cv=4, n_jobs=-3, param_grid=param_grid, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================ Ignore the following ===================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "train_tr shape (755, 29)\n",
      "\t mean (0.8609271523178808, 0.835820895522388)\n",
      "train_tr shape (755, 29)\n",
      "\t median (0.8649006622516556, 0.8582089552238806)\n",
      "train_tr shape (755, 29)\n",
      "\t function (0.8609271523178808, 0.8432835820895522)\n",
      "train_tr shape (755, 29)\n",
      "\t zeros (0.8582781456953642, 0.8432835820895522)\n",
      " \n",
      "log\n",
      "train_tr shape (755, 29)\n",
      "\t mean (0.833112582781457, 0.8134328358208955)\n",
      "train_tr shape (755, 29)\n",
      "\t median (0.833112582781457, 0.8134328358208955)\n",
      "train_tr shape (755, 29)\n",
      "\t function (0.833112582781457, 0.8134328358208955)\n",
      "train_tr shape (755, 29)\n",
      "\t zeros (0.8304635761589404, 0.8134328358208955)\n",
      " \n",
      "svc\n",
      "train_tr shape (755, 29)\n",
      "\t mean (0.8423841059602649, 0.8208955223880597)\n",
      "train_tr shape (755, 29)\n",
      "\t median (0.8423841059602649, 0.8208955223880597)\n",
      "train_tr shape (755, 29)\n",
      "\t function (0.8423841059602649, 0.8208955223880597)\n",
      "train_tr shape (755, 29)\n",
      "\t zeros (0.8397350993377484, 0.8208955223880597)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "selected_models = ['knn', 'log', 'svc'] \n",
    "\n",
    "imputation_methods = ['mean', 'median', 'function', 'zeros']\n",
    "\n",
    "for i in selected_models:\n",
    "    print(i)\n",
    "    for j in imputation_methods:\n",
    "        print('\\t',j, base_pip(models[i], data, labels, imputer_s=j))\n",
    "    print(' ')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different imputation methods have little impact on train and test for LR and SVC. KNN is slightly less stable from this standpoint, but it remains the best performing model, with the median as imputation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have chosen our model, we can grid search parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tr shape with gscv (889, 29)\n",
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-3)]: Done  40 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-3)]: Done 360 out of 360 | elapsed:    3.3s finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'weights': ['uniform', 'distance'], \n",
    "               'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "               'n_neighbors': np.linspace(1, 15, 15).astype(int)}\n",
    "\n",
    "best_cv = base_pip(models['knn'], data, labels, \n",
    "                   imputer_s='median', option='grid_search', \n",
    "                   param_grid=param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tr shape (755, 29)\n",
      "best (0.8370860927152318, 0.8283582089552238)\n"
     ]
    }
   ],
   "source": [
    "models = {'best': best_cv['best_estimator']}\n",
    "\n",
    "\n",
    "for i, j in models.items():\n",
    "    print(i, base_pip(j, data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_unknown = pd.read_csv(path / 'test.csv')\n",
    "X_unknown.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "X_unknown.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unknown.dropna(subset=['Fare'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unknown.drop(['Cabin', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ = X_unknown.Name.apply(lambda x:x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "X_unknown['Title'] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unknown.drop(['Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 417 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    417 non-null    int64  \n",
      " 1   Sex       417 non-null    object \n",
      " 2   Age       331 non-null    float64\n",
      " 3   SibSp     417 non-null    int64  \n",
      " 4   Parch     417 non-null    int64  \n",
      " 5   Fare      417 non-null    float64\n",
      " 6   Embarked  417 non-null    object \n",
      " 7   Title     416 non-null    object \n",
      "dtypes: float64(2), int64(3), object(3)\n",
      "memory usage: 29.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X_unknown.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_wparams = best_cv['pipeline'].set_params(**best_cv['pipeline_params'])\n",
    "X_unknown.dropna(subset=['Title'], inplace=True)\n",
    "pipeline = best_cv['pipeline']\n",
    "X_unknown_tr = pipeline.fit_transform(X_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 29)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pipeline.fit_transform(data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported type: <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0b47f4473cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_unknown_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_unknown_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_unknown_tr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   3822\u001b[0m         \u001b[0mbroadcast_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3823\u001b[0m     ) -> \"DataFrame\":\n\u001b[0;32m-> 3824\u001b[0;31m         return super().align(\n\u001b[0m\u001b[1;32m   3825\u001b[0m             \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3826\u001b[0m             \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   8487\u001b[0m             )\n\u001b[1;32m   8488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8489\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unsupported type: {type(other)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8491\u001b[0m     def _align_frame(\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported type: <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "X_unknown_tr = X_train.align(X_unknown_tr, axis=1)\n",
    "X_unknown_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 20 while Y.shape[1] == 28",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d00fb12851b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_estimator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_unknown_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[1;32m    642\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0m\u001b[1;32m   1617\u001b[0m                                      n_jobs=n_jobs, **kwds)\n\u001b[1;32m   1618\u001b[0m         if ((X is Y or Y is None)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1777\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0mpaired_distances\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0mbetweens\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0mof\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \"\"\"\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;31m# If norms are passed as float32, they are unused. If arrays are passed as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    157\u001b[0m                              (X.shape[0], X.shape[1], Y.shape[0]))\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[0m\u001b[1;32m    160\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[1;32m    161\u001b[0m                              X.shape[1], Y.shape[1]))\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 20 while Y.shape[1] == 28"
     ]
    }
   ],
   "source": [
    "predictions = best_cv['best_estimator'].predict(X_unknown_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
