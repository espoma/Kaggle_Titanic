{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kaggle_Titanic_utls import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = Path('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the data and do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv(PATH_DATA / \"train.csv\")\n",
    "test = pd.read_csv(PATH_DATA / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 12), (418, 11))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3838383838383838"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Survived'].sum()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are sufficiently balanced - it makes sense to consider accuracy as performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.dropna(subset=['Embarked'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[['Survived']]\n",
    "data.drop(['Cabin', 'Ticket', 'PassengerId', 'Survived'], axis=1, inplace=True)\n",
    "\n",
    "test_ids = test.PassengerId\n",
    "test.drop(['Cabin', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_c6bb8_row0_col0,#T_c6bb8_row1_col1,#T_c6bb8_row2_col2,#T_c6bb8_row3_col3,#T_c6bb8_row4_col4{\n",
       "            background-color:  #ff00ff;\n",
       "            color:  #f1f1f1;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row0_col1,#T_c6bb8_row0_col4,#T_c6bb8_row1_col2,#T_c6bb8_row1_col3,#T_c6bb8_row4_col0{\n",
       "            background-color:  #00ffff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row0_col2{\n",
       "            background-color:  #4cb3ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row0_col3{\n",
       "            background-color:  #2cd3ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row1_col0{\n",
       "            background-color:  #1de2ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row1_col4{\n",
       "            background-color:  #6a95ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row2_col0{\n",
       "            background-color:  #6897ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row2_col1{\n",
       "            background-color:  #0bf4ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row2_col3{\n",
       "            background-color:  #827dff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row2_col4{\n",
       "            background-color:  #758aff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row3_col0{\n",
       "            background-color:  #5da2ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row3_col1{\n",
       "            background-color:  #21deff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row3_col2{\n",
       "            background-color:  #8d72ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row3_col4{\n",
       "            background-color:  #7e81ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row4_col1{\n",
       "            background-color:  #56a9ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row4_col2{\n",
       "            background-color:  #5ba4ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }#T_c6bb8_row4_col3{\n",
       "            background-color:  #57a8ff;\n",
       "            color:  #000000;\n",
       "            font-size:  15px;\n",
       "        }</style><table id=\"T_c6bb8_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Pclass</th>        <th class=\"col_heading level0 col1\" >Age</th>        <th class=\"col_heading level0 col2\" >SibSp</th>        <th class=\"col_heading level0 col3\" >Parch</th>        <th class=\"col_heading level0 col4\" >Fare</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c6bb8_level0_row0\" class=\"row_heading level0 row0\" >Pclass</th>\n",
       "                        <td id=\"T_c6bb8_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "                        <td id=\"T_c6bb8_row0_col1\" class=\"data row0 col1\" >-0.369226</td>\n",
       "                        <td id=\"T_c6bb8_row0_col2\" class=\"data row0 col2\" >0.083081</td>\n",
       "                        <td id=\"T_c6bb8_row0_col3\" class=\"data row0 col3\" >0.018443</td>\n",
       "                        <td id=\"T_c6bb8_row0_col4\" class=\"data row0 col4\" >-0.549500</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c6bb8_level0_row1\" class=\"row_heading level0 row1\" >Age</th>\n",
       "                        <td id=\"T_c6bb8_row1_col0\" class=\"data row1 col0\" >-0.369226</td>\n",
       "                        <td id=\"T_c6bb8_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "                        <td id=\"T_c6bb8_row1_col2\" class=\"data row1 col2\" >-0.308247</td>\n",
       "                        <td id=\"T_c6bb8_row1_col3\" class=\"data row1 col3\" >-0.189119</td>\n",
       "                        <td id=\"T_c6bb8_row1_col4\" class=\"data row1 col4\" >0.096067</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c6bb8_level0_row2\" class=\"row_heading level0 row2\" >SibSp</th>\n",
       "                        <td id=\"T_c6bb8_row2_col0\" class=\"data row2 col0\" >0.083081</td>\n",
       "                        <td id=\"T_c6bb8_row2_col1\" class=\"data row2 col1\" >-0.308247</td>\n",
       "                        <td id=\"T_c6bb8_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "                        <td id=\"T_c6bb8_row2_col3\" class=\"data row2 col3\" >0.414838</td>\n",
       "                        <td id=\"T_c6bb8_row2_col4\" class=\"data row2 col4\" >0.159651</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c6bb8_level0_row3\" class=\"row_heading level0 row3\" >Parch</th>\n",
       "                        <td id=\"T_c6bb8_row3_col0\" class=\"data row3 col0\" >0.018443</td>\n",
       "                        <td id=\"T_c6bb8_row3_col1\" class=\"data row3 col1\" >-0.189119</td>\n",
       "                        <td id=\"T_c6bb8_row3_col2\" class=\"data row3 col2\" >0.414838</td>\n",
       "                        <td id=\"T_c6bb8_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
       "                        <td id=\"T_c6bb8_row3_col4\" class=\"data row3 col4\" >0.216225</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c6bb8_level0_row4\" class=\"row_heading level0 row4\" >Fare</th>\n",
       "                        <td id=\"T_c6bb8_row4_col0\" class=\"data row4 col0\" >-0.549500</td>\n",
       "                        <td id=\"T_c6bb8_row4_col1\" class=\"data row4 col1\" >0.096067</td>\n",
       "                        <td id=\"T_c6bb8_row4_col2\" class=\"data row4 col2\" >0.159651</td>\n",
       "                        <td id=\"T_c6bb8_row4_col3\" class=\"data row4 col3\" >0.216225</td>\n",
       "                        <td id=\"T_c6bb8_row4_col4\" class=\"data row4 col4\" >1.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f496bdfeb50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr().style.background_gradient(cmap ='cool')\\\n",
    "        .set_properties(**{'font-size': '15px'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the title of each passenger from the name as the former likely bears more significance than the latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "title = get_title(data)\n",
    "test_title = get_title(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              517\n",
       "Miss            182\n",
       "Mrs             125\n",
       "Master           40\n",
       "Dr                7\n",
       "Rev               6\n",
       "Major             2\n",
       "Mlle              2\n",
       "Col               2\n",
       "Ms                1\n",
       "Sir               1\n",
       "the Countess      1\n",
       "Don               1\n",
       "Jonkheer          1\n",
       "Lady              1\n",
       "Mme               1\n",
       "Capt              1\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'] = title\n",
    "data.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "test['Title'] = test_title\n",
    "test.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide whether to use passengers titles or drop these also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_title = True\n",
    "if (no_title):\n",
    "    try:\n",
    "        data.drop('Title', axis=1, inplace=True)\n",
    "        test.drop('Title', axis=1, inplace=True)\n",
    "    except KeyError:\n",
    "        print('Title is not present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 1), (891, 7))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we impute numerical and categorical features with median and mode, respectively, and then we transform categorical features using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_num, data_cat = get_features_by_type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer()),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['Embarked', 'Sex', 'Pclass']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "data_ = preprocessor.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = preprocessor.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 13), (418, 13))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_.shape, test_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at various baseline models to check which ones give the best score in and out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[91m\u001b[4mknn scores\u001b[0m: {'train_score': 0.8622754491017964, 'test_score': 0.7847533632286996}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mLR scores\u001b[0m: {'train_score': 0.8083832335329342, 'test_score': 0.7937219730941704}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mtree scores\u001b[0m: {'train_score': 0.9865269461077845, 'test_score': 0.7847533632286996}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mGNB scores\u001b[0m: {'train_score': 0.6736526946107785, 'test_score': 0.7174887892376681}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mperceptron scores\u001b[0m: {'train_score': 0.7664670658682635, 'test_score': 0.7937219730941704}\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[91m\u001b[4mSVC scores\u001b[0m: {'train_score': 0.8413173652694611, 'test_score': 0.8251121076233184}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {'knn': KNeighborsClassifier(), 'LR': LogisticRegression(), \n",
    "         'tree': DecisionTreeClassifier(), 'GNB': GaussianNB(),\n",
    "         'perceptron': Perceptron(), 'SVC': SVC()}\n",
    "\n",
    "for i, j in models.items():\n",
    "    scores = model_trial(data_, labels, j)\n",
    "    print(color.BOLD + color.RED + color.UNDERLINE + f'{i} scores' + color.END + f': {scores}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron and Naive Bayes have a poor accuracy, whereas Decision Trees are clearly overfitting to the training set. SVC, Logistic Regression and KNN perform reasonably well in and out of sample (random guessing would yield around $62 \\%$ accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take the best models and preprocessing strategies and grid search the best parameters using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search: knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'weights': ['uniform', 'distance'], \n",
    "               'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "               'n_neighbors': np.linspace(1, 15, 15).astype(int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(models['knn'], cv=4, n_jobs=-3, param_grid=param_grid, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "CPU times: user 300 ms, sys: 45 ms, total: 345 ms\n",
      "Wall time: 1.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=KNeighborsClassifier(), n_jobs=-3,\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15]),\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gscv.fit(data_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(KNeighborsClassifier(algorithm='ball_tree', n_neighbors=12),\n",
       " {'algorithm': 'ball_tree', 'n_neighbors': 12, 'weights': 'uniform'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_, gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=12)\n",
      "model: knn_BE\n",
      "train score: 0.8383\n",
      "test score: 0.7758\n"
     ]
    }
   ],
   "source": [
    "model = gscv.best_estimator_\n",
    "name_model = 'knn_BE'\n",
    "try_model(data_, labels, model, name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subfile_titanic(test_, test_ids, model, name_model, PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 2.77k/2.77k [00:03<00:00, 741B/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f \"submission_{name_model}_titanic.csv\" -m 'submission of {model}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search: lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'penalty': ['l1'], 'solver': ['liblinear', 'saga'], \n",
    "                'C': np.logspace(-2, 2, 5, 10)},\n",
    "               {'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                'C': np.logspace(-2, 2, 5, 10)},\n",
    "               {'penalty': ['elasticnet'], 'solver': ['saga'], \n",
    "                'l1_ratio': np.arange(0.1, 1, 0.1), 'C': np.logspace(-2, 2, 5, 10)},\n",
    "                {'penalty': [None], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(models['LR'], cv=4, n_jobs=-3, param_grid=param_grid, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 79 candidates, totalling 316 fits\n",
      "CPU times: user 332 ms, sys: 35.7 ms, total: 367 ms\n",
      "Wall time: 1.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LogisticRegression(), n_jobs=-3,\n",
       "             param_grid=[{'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                          'penalty': ['l1'], 'solver': ['liblinear', 'saga']},\n",
       "                         {'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                          'penalty': ['l2'],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']},\n",
       "                         {'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                          'l1_ratio': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                          'penalty': ['elasticnet'], 'solver': ['saga']},\n",
       "                         {'penalty': [None],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}],\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gscv.fit(data_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=10.0, penalty='l1', solver='liblinear'),\n",
       " {'C': 10.0, 'penalty': 'l1', 'solver': 'liblinear'})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_, gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10.0, penalty='l1', solver='liblinear')\n",
      "model: lr_BE\n",
      "train score: 0.8204\n",
      "test score: 0.7892\n"
     ]
    }
   ],
   "source": [
    "model = gscv.best_estimator_\n",
    "name_model = 'lr_BE'\n",
    "try_model(data_, labels, model, name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subfile_titanic(test_, test_ids, model, name_model, PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c titanic -f \"submission_{name_model}_titanic.csv\" -m 'submission of {model}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search: svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': np.logspace(-2, 2, 5, 10),\n",
    "               'kernel': ['linear', 'rbf', 'poly'],\n",
    "              'degree': np.linspace(2, 5, 5).astype(int)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(models['SVC'], cv=4, n_jobs=-3, param_grid=param_grid, scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 75 candidates, totalling 300 fits\n",
      "CPU times: user 266 ms, sys: 33.6 ms, total: 299 ms\n",
      "Wall time: 3.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=SVC(), n_jobs=-3,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'degree': array([2, 2, 3, 4, 5]),\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gscv.fit(data_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(SVC(degree=2), {'C': 1.0, 'degree': 2, 'kernel': 'rbf'})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_estimator_, gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(degree=2)\n",
      "model: svc_BE\n",
      "train score: 0.8488\n",
      "test score: 0.7982\n"
     ]
    }
   ],
   "source": [
    "model = gscv.best_estimator_\n",
    "name_model = 'svc_BE'\n",
    "try_model(data_, labels, model, name_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Classifier with a quadratic polynomial kernel and strength of the regularization equal to $C=1$ yields the best accuracy after grid-searching parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subfile_titanic(test_, test_ids, model, name_model, PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c titanic -f \"submission_{name_model}_titanic.csv\" -m 'submission of {model}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use some ensemble methods on this dataset. We will first try with hard and soft voting classifiers, and then with Random Forest and Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=100)\n",
      "model: rf_titanic\n",
      "train score: 0.9850\n",
      "test score: 0.8161\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=100)\n",
    "name_model = 'rf_titanic'\n",
    "save_model = 'no'\n",
    "try_model(data_, labels, model, name_model, dump_model=save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subfile_titanic(test_, test_ids, model, name_model, PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 2.77k/2.77k [00:02<00:00, 972B/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f \\\n",
    "\"submission_{name_model}_titanic.csv\" -m \\\n",
    "'submission of {name_model}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier(random_state=10)\n",
      "model: ext_titanic\n",
      "train score: 0.9865\n",
      "test score: 0.7982\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier(random_state=10)\n",
    "name_model = 'ext_titanic'\n",
    "save_model = 'no'\n",
    "try_model(data_, labels, model, name_model, dump_model=save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subfile_titanic(test_, test_ids, model, name_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search parameters for ensemble methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard and Soft Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset seems to be very simple, so it make sense to train several weak learners and combine them using soft or hard voting classifiers. Let's see how these two strategies perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('svc', SVC(kernel='poly')),\n",
      "                             ('lr', LogisticRegression()),\n",
      "                             ('dt', DecisionTreeClassifier()),\n",
      "                             ('gnb', GaussianNB()),\n",
      "                             ('knn', KNeighborsClassifier())],\n",
      "                 n_jobs=-3, verbose=True)\n",
      "model: hv_clf_titanic\n",
      "train score: 0.8713\n",
      "test score: 0.7892\n"
     ]
    }
   ],
   "source": [
    "model = VotingClassifier(estimators=[('svc', SVC(kernel='poly')), \\\n",
    "('lr', LogisticRegression()), ('dt', DecisionTreeClassifier()),\\\n",
    "('gnb', GaussianNB()), ('knn', KNeighborsClassifier())], \\\n",
    "voting='hard', n_jobs=-3, verbose=True)\n",
    "\n",
    "name_model = 'hv_clf_titanic'\n",
    "try_model(data_, labels, model, name_model, dump_model='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier(estimators=[('svc', SVC(probability=True)),\n",
      "                             ('lr', LogisticRegression()),\n",
      "                             ('dt', DecisionTreeClassifier()),\n",
      "                             ('gnb', GaussianNB()),\n",
      "                             ('knn', KNeighborsClassifier())],\n",
      "                 n_jobs=-3, verbose=True, voting='soft')\n",
      "model: sv_clf_titanic\n",
      "train score: 0.8937\n",
      "test score: 0.7803\n"
     ]
    }
   ],
   "source": [
    "model = VotingClassifier(estimators=[('svc', SVC(probability=True)), \\\n",
    "('lr', LogisticRegression()), ('dt', DecisionTreeClassifier()),\\\n",
    "('gnb', GaussianNB()), ('knn', KNeighborsClassifier())], \\\n",
    "voting='soft', n_jobs=-3, verbose=True)\n",
    "\n",
    "name_model = 'sv_clf_titanic'\n",
    "try_model(data_, labels, model, name_model, dump_model='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subfile_titanic(test_, test_ids, model, name_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2.77k/2.77k [00:02<00:00, 1.02kB/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f \\\n",
    "\"submission_{name_model}_titanic.csv\" -m \\\n",
    "'submission of {name_model}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n",
      "CPU times: user 234 ms, sys: 56.5 ms, total: 291 ms\n",
      "Wall time: 2.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=GradientBoostingClassifier(), n_jobs=-3,\n",
       "             param_grid={'n_estimators': array([ 10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,  70,\n",
       "        75,  80,  85,  90,  95, 100])},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_estimators': np.arange(10, 101, 5)}\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "gscv = GridSearchCV(clf, scoring='accuracy', cv=10,\\\n",
    "param_grid=param_grid, verbose=1, n_jobs=-3)\n",
    "\n",
    "gscv.fit(data_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8238202247191012"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, name_model = gscv.best_estimator_, 'xgb_BE_titanic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473625140291807"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert create_subfile_titanic(test_,\\\n",
    "test_ids, model, name_model) == 0, 'something wrong in creating submission file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 2.77k/2.77k [00:04<00:00, 681B/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f \\\n",
    "\"submission_{name_model}_titanic.csv\" -m \\\n",
    "'submission of {name_model}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n",
      "CPU times: user 391 ms, sys: 21.6 ms, total: 412 ms\n",
      "Wall time: 4.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=AdaBoostClassifier(), n_jobs=-3,\n",
       "             param_grid={'n_estimators': array([ 10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,  65,  70,\n",
       "        75,  80,  85,  90,  95, 100])},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {'n_estimators': np.arange(10, 101, 5)}\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "gscv = GridSearchCV(clf, scoring='accuracy', cv=10,\\\n",
    "param_grid=param_grid, verbose=1, n_jobs=-3)\n",
    "\n",
    "gscv.fit(data_, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8126342072409489"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, name_model = gscv.best_estimator_, 'adab_BE_titanic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert create_subfile_titanic(test_,\\\n",
    "test_ids, model, name_model) == 0, 'something wrong in creating submission file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 2.77k/2.77k [00:04<00:00, 616B/s]\n",
      "Successfully submitted to Titanic - Machine Learning from Disaster"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c titanic -f \\\n",
    "\"submission_{name_model}_titanic.csv\" -m \\\n",
    "'submission of {name_model}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
